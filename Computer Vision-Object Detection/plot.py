import matplotlib.pyplot as plt
import numpy as np
#default ls1e-4 batch size=2 epoch=20 depth=50
# [1.4906988944124988, 1.1628603570925908, 1.0056641383433904, 0.9069616570482104, 0.8269023423002461, 0.7594464036130061, 0.6962992794899725, 0.6463149883381025, 0.5862711948584619, 0.5518393734191346, 0.508970759391022, 0.47122546640320084, 0.4358931640456394, 0.4034902395489882, 0.37366002893412675, 0.3473574042862912, 0.33051742310452414, 0.31041847738459355, 0.2910840312004324, 0.280807738577375]
loss_1 = [1.4906988944124988, 1.1628603570925908, 1.0056641383433904, 0.9069616570482104, 0.8269023423002461, 0.7594464036130061, 0.6962992794899725, 0.6463149883381025, 0.5862711948584619, 0.5518393734191346, 0.508970759391022, 0.47122546640320084, 0.4358931640456394, 0.4034902395489882, 0.37366002893412675, 0.3473574042862912, 0.33051742310452414, 0.31041847738459355, 0.2910840312004324, 0.280807738577375]

#batch size=4
#[1.4955191222701485, 1.1688021304100518, 0.996396796557847, 0.8941603314688825, 0.8165884438579477, 0.7494665482851464, 0.6819384098052979, 0.6312400914552644, 0.5833331752480484, 0.5363871375700151, 0.501395848616371, 0.45652520369122346, 0.4335470123319175, 0.40183467539687323, 0.3695594310819164, 0.35064685019099806, 0.32714972341447834, 0.2990299394046228, 0.2770135154962305, 0.2650971022236535]
loss_2=[1.4955191222701485, 1.1688021304100518, 0.996396796557847, 0.8941603314688825, 0.8165884438579477, 0.7494665482851464, 0.6819384098052979, 0.6312400914552644, 0.5833331752480484, 0.5363871375700151, 0.501395848616371, 0.45652520369122346, 0.4335470123319175, 0.40183467539687323, 0.3695594310819164, 0.35064685019099806, 0.32714972341447834, 0.2990299394046228, 0.2770135154962305, 0.2650971022236535]

#lr=1e-5
#[1.2392994169527152, 0.90988638674415, 0.7670130207547992, 0.6756171857659506, 0.6033423524349928, 0.5466473582750699, 0.4950357211577728, 0.45074064782490647, 0.4209655546399904, 0.3868543403589819, 0.36266371933376695, 0.3373354173808058, 0.3201355316683533, 0.3022931285393168, 0.2878826760070941, 0.26878885273990316, 0.26028572334944616, 0.24754897340046844, 0.23842753915805517, 0.23016251117269707]
loss_3=[1.2392994169527152, 0.90988638674415, 0.7670130207547992, 0.6756171857659506, 0.6033423524349928, 0.5466473582750699, 0.4950357211577728, 0.45074064782490647, 0.4209655546399904, 0.3868543403589819, 0.36266371933376695, 0.3373354173808058, 0.3201355316683533, 0.3022931285393168, 0.2878826760070941, 0.26878885273990316, 0.26028572334944616, 0.24754897340046844, 0.23842753915805517, 0.23016251117269707]

#101
#[1.2132674893437643, 0.8870513707575366, 0.7338674558605266, 0.6367798400822822, 0.5657444075923267, 0.5056505690394776, 0.4587076452274726, 0.41784111857707573, 0.385900890014655, 0.35797626363098856, 0.3345342678472576, 0.3131719407713495, 0.2947622408364408, 0.2808680572789016, 0.265864157510232, 0.25476833533378335, 0.23820710509619492, 0.23433947680136702, 0.22017361529860793, 0.2135633529369228]
loss_4=[1.2132674893437643, 0.8870513707575366, 0.7338674558605266, 0.6367798400822822, 0.5657444075923267, 0.5056505690394776, 0.4587076452274726, 0.41784111857707573, 0.385900890014655, 0.35797626363098856, 0.3345342678472576, 0.3131719407713495, 0.2947622408364408, 0.2808680572789016, 0.265864157510232, 0.25476833533378335, 0.23820710509619492, 0.23433947680136702, 0.22017361529860793, 0.2135633529369228]
epochs = range(1, len(loss_1) + 1)

plt.plot(epochs, loss_1, label='Model A')
plt.plot(epochs, loss_2, label='Model B')
plt.plot(epochs, loss_3, label='Model C')
plt.plot(epochs, loss_4, label='Model D')
plt.title('Training Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
xticks = np.arange(min(epochs)-1, max(epochs)+1, 5)
plt.xticks(xticks)
plt.show()